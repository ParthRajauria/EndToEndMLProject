################################ End to End ML Project ##########################

Topics to Cover

0. Set up project with github.
1. Data Ingestion
2. Data Transformation
3. Model Trainer
4. Model Evaluation
5. Model Deployment


CI/CD Pipelines - Github Actions
Deployment - AWS

############################ What Did I Learn ########################
Point 1 - How to create a modular code design and how to design ml workflow.



######## Steps in each Tutorial    #########


#####  Tutorial 1 - Github and Code Setup    ######

Step 1 - Create a repository in github
Step 2 - Go to vs code in your project directory, open terminal and create a virtual environment
Step 3 - Sync the github repository with vs code. So that we can commit all our code to github easily. 
Step 4 - Create a gitignore file in github. We use this so that the files/libraries that are not committed on github can be removed and can free up space and increase computational power. Use git pull to pull the files from github repository to vs code.
Step 5 - Create setup.py file. This file will be responsible for creating our machine learning application as a package. And we can use this package later for any other project.
Step 6 - Create a folder called src, and create a file in this src folder called __init__.py
Step 7 - Now install all the dependencies by running pip install -r requirements.txt


##### Tutorial 2 - Project Structure, Logging, and Exception Handling.

Step 1 - create a components folder under src folder. In that, create a __init__.py file. Components will contain all the modules, like data ingestion. EDA, etc. 
Step 2 - create a pipeline directory. In that have training and testing pipeline. 
Step 3 - Create 3 more files, utils.py (for writing generic functions that are used everywhere), exception.py (for exception handling), and logger.py (for data logging)
Step 4 - Write code on exception.py file. 

#### Tutorial 3 - Project Problem Statement, EDA, and Model Training. 

Step 1 - Create repository notebook.
Step 2 - Copy data and EDA notebooks and Model Training notebook from krish naik repository to this repo. 
Step 3 - Execute EDA notebook one by one.

### Tutorial 4 - Data Ingestion implementation line by line.
Step 1 - Work on the data_ingestion.py file present inside src/components directory. Include data ingestion pipeline with proper logs.


### Tutorial 5 - Data Transformation implementation using pipeline.
Step 1 - Add the code in data_transformation.py file.
Step 2 - Add the code of saving object in utlis.py
Step 3 - Add the code of calling data_transformation in data_ingestion.py file.